{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring OOI data access\n",
    "\n",
    "Still not sure how everything works, so this script is going to be my exploration into loading broadband hydrophone data.\n",
    "\n",
    "I'm using this notebook as an example: https://github.com/petercable/noisy-dolphins/blob/master/Voices.ipynb \n",
    "\n",
    "But rather than loading up one specific file, I'm interested in providing the user with a way to explore the available data a little bit. I plan to use beautiful soup to scrape the particular corner of the OOI raw data website that I'm interested in. It may not be the best way to do it but I currently don't know a better way so here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up and scraping data\n",
    "\n",
    "I'm starting by specifying the URL to the page I'm interested in. (I've also specified a particular miniseed file but commenting that out for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_mseed = 'https://rawdata.oceanobservatories.org/files/RS03AXBS/LJ03A/09-HYDBBA302/2020/12/05/OO-AXVM1--YDH-2020-12-05T14:30:00.000015.mseed'\n",
    "# print('The requested URL: ' + url_mseed)\n",
    "\n",
    "page_url = 'https://rawdata.oceanobservatories.org/files/RS03AXBS/LJ03A/09-HYDBBA302/2020/12/05/'\n",
    "page = requests.get(page_url).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll use beautiful soup to parse the contents of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "# Uncomment to see the full html\n",
    "# print(soup.prettify()) \n",
    "# pull out every link on the page\n",
    "all_links = [link.get('href') for link in soup.find_all('a')]\n",
    "mseed_files = [i for i in all_links if '.mseed' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obskernel",
   "language": "python",
   "name": "obskernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
